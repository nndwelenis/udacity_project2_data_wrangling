# Wrangling and Analyze Data
## by Nndweleni Sundani


## Introduction

Real-world data rarely comes clean. In this project, i used Python and its libraries to gather data from a variety of sources and in a variety of formats, assess its quality and tidiness, then clean it. This is called data wrangling. I will document my wrangling efforts in a Jupyter Notebook, plus showcase them through analyses and visualizations using Python (and its libraries).

## Dataset

The dataset used is the tweet archive of Twitter user @dog_rates, also known as WeRateDogs. WeRateDogs is a Twitter account that rates peopleâ€™s dogs with humorous comments. WeRateDogs downloaded their Twitter archive and sent it to Udacity via email exclusively for use in this project. This archive contains basic tweet data (tweet ID, timestamp, text, etc.) for all 5000+ of their tweets as they stood on August 1, 2017.

## What Software Do I Need?  

You need to be able to work in a Jupyter Notebook on your computer.

The following packages (libraries) need to be installed. You can install these packages via conda or pip.

Pandas
NumPy
requests
tweepy
json
